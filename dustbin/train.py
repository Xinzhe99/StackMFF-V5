import argparse
import time
import sys
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import platform
from datetime import datetime
from torch.optim import AdamW
from torch.optim.lr_scheduler import ExponentialLR
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# === è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥ ===
# ç¡®ä¿ Dataloader.py, network.py, loss.py, utils.py åœ¨åŒä¸€ç›®å½•ä¸‹
from Dataloader import get_updated_dataloader
from network_v1 import StackMFF_V5 
# ä¿®æ”¹ç‚¹1: å¯¼å…¥ SpatialSmoothnessLoss ä»¥ä¾¿åœ¨éªŒè¯é›†æ‰‹åŠ¨è®¡ç®—
from loss import FusionLoss, SpatialSmoothnessLoss
from utils import (to_image, count_parameters, config_model_dir, 
                   print_banner, print_model_info, print_device_info, 
                   print_dataset_info, print_training_config, 
                   print_epoch_results, print_training_complete)

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(description="StackMFF Training Script (Ordered/Unordered)")
    
    # === æ ¸å¿ƒå®éªŒå‚æ•° ===
    parser.add_argument('--loss_mode', type=str, default='ordered', choices=['ordered', 'unordered'],
                        help="Training mode: 'ordered' (OT Loss) or 'unordered' (KL Divergence)")
    parser.add_argument('--lambda_spatial', type=float, default=0.01,
                        help="Weight for spatial smoothness regularization (Horizontal Loss)")
    parser.add_argument('--save_name', default='stackmff_training',
                        help="Name of the experiment for saving logs and models")
    
    # === æ•°æ®é›†é…ç½® ===
    # è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…æ•°æ®é›†æ ¹ç›®å½•
    parser.add_argument('--datasets_root', 
                        default=r'/media/user/dataset/stackmff_v3_dataset',
                        type=str, help='Root path to all datasets')

    parser.add_argument('--train_datasets', nargs='+', 
                        default=['NYU-V2', 'DUTS', 'DIODE', 'Cityscapes', 'ADE'],
                        help='List of datasets to use for training')
    parser.add_argument('--val_datasets', nargs='+',
                        default=['NYU-V2', 'DUTS', 'DIODE', 'Cityscapes', 'ADE'],
                        help='List of datasets to use for validation')
    
    parser.add_argument('--subset_fraction_train', type=float, default=0.2,
                        help='Fraction of training data to use (0-1)')
    parser.add_argument('--subset_fraction_val', type=float, default=0.05,
                        help='Fraction of validation data to use (0-1)')

    # === è®­ç»ƒè¶…å‚æ•° ===
    parser.add_argument('--training_image_size', type=int, default=256,
                        help='Target image size for training (Resize)')
    parser.add_argument('--batch_size', type=int, default=8, 
                        help='Batch size')
    parser.add_argument('--num_epochs', type=int, default=50, 
                        help='Number of training epochs')
    parser.add_argument('--eval_interval', type=int, default=1, 
                        help='Interval of epochs between evaluations')
    parser.add_argument('--lr', type=float, default=1e-3, 
                        help='Initial learning rate')
    parser.add_argument('--lr_decay', type=float, default=0.9, 
                        help='Learning rate decay factor per epoch')
    parser.add_argument('--num_workers', type=int, default=8, 
                        help='Number of data loading workers')
    
    # === ç¡¬ä»¶é…ç½® ===
    parser.add_argument('--gpu_ids', nargs='+', type=int, default=None,
                        help='Specific GPU IDs to use (e.g., 0 1). Default: use all.')
    
    return parser.parse_args()

def create_dataset_loaders(args):
    """
    Create training and validation data loaders.
    """
    # === å…³é”®é€»è¾‘ï¼šæ ¹æ® loss_mode å†³å®šæ˜¯å¦æ‰“ä¹±é¡ºåº ===
    should_shuffle = (args.loss_mode == 'unordered')
    
    if should_shuffle:
        print("ğŸ”€ Dataloader: Layer shuffling ENABLED (Unordered Mode)")
    else:
        print("â¬‡ï¸ Dataloader: Layer shuffling DISABLED (Ordered Mode)")

    # -------------------------------------------------
    # 1. åˆ›å»ºè®­ç»ƒé›† Loader
    # -------------------------------------------------
    train_dataset_params = []
    for dataset_name in args.train_datasets:
        dataset_path = os.path.join(args.datasets_root, dataset_name, 'TR')
        
        # ä¸¥æ ¼æŒ‡å®š soft_gt è·¯å¾„
        gt_path = os.path.join(dataset_path, 'soft_gt')
        img_path = os.path.join(dataset_path, 'focus_stack')
             
        # æ£€æŸ¥å›¾åƒå’ŒGTè·¯å¾„æ˜¯å¦éƒ½å­˜åœ¨
        if os.path.exists(img_path) and os.path.exists(gt_path):
            train_dataset_params.append({
                'root_dir': img_path,
                'soft_gt_dir': gt_path,
                'subset_fraction': args.subset_fraction_train
            })
        else:
            print(f"âš ï¸  Warning: Training dataset or Soft GT not found at: {dataset_path}")
    
    train_loader = None
    if train_dataset_params:
        train_loader = get_updated_dataloader(
            train_dataset_params,
            batch_size=args.batch_size,
            num_workers=args.num_workers,
            augment=True,
            target_size=args.training_image_size,
            shuffle_order=should_shuffle 
        )
    
    # -------------------------------------------------
    # 2. åˆ›å»ºéªŒè¯é›† Loader (åˆ—è¡¨)
    # -------------------------------------------------
    val_loaders = []
    for dataset_name in args.val_datasets:
        dataset_path = os.path.join(args.datasets_root, dataset_name, 'TE')
        
        gt_path = os.path.join(dataset_path, 'soft_gt')
        img_path = os.path.join(dataset_path, 'focus_stack')

        if os.path.exists(img_path) and os.path.exists(gt_path):
            val_loader = get_updated_dataloader(
                [{
                    'root_dir': img_path,
                    'soft_gt_dir': gt_path,
                    'subset_fraction': args.subset_fraction_val
                }],
                batch_size=args.batch_size,
                num_workers=args.num_workers,
                augment=False,
                target_size=args.training_image_size,
                shuffle_order=should_shuffle 
            )
            if val_loader is not None:
                val_loaders.append(val_loader)
        else:
            print(f"âš ï¸  Warning: Validation dataset or Soft GT not found at: {dataset_path}")
    
    return train_loader, val_loaders

def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, total_epochs):
    """
    è®­ç»ƒå•ä¸ª Epoch
    """
    model.train()
    total_loss = 0.0
    
    progress_bar = tqdm(
        train_loader, 
        desc=f"ğŸ”¥ Epoch {epoch+1}/{total_epochs} [Train]",
        ncols=120,
        bar_format='{l_bar}{bar:20}{r_bar}'
    )

    for batch_idx, (image_stack, soft_gt, stack_size) in enumerate(progress_bar):
        # image_stack: [B, N, H, W]
        # soft_gt: [B, N, H, W] (Float32)
        image_stack, soft_gt = image_stack.to(device), soft_gt.to(device)

        optimizer.zero_grad()
        
        # è®­ç»ƒæ¨¡å¼ä¸‹ï¼ŒNetwork è¿”å› logits [B, N, H, W]
        logits = model(image_stack)
        
        # è®¡ç®— Loss (FusionLoss å†…éƒ¨å¤„ç† OT/KL å’Œ Spatial)
        loss = criterion(logits, soft_gt)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.set_postfix({
            "Loss": f"{loss.item():.4f}",
            "Avg": f"{total_loss/(batch_idx+1):.4f}",
        })

    return total_loss / len(train_loader)

def validate_dataset(model, val_loader, device, epoch, save_path, dataset_name, loss_mode, lambda_spatial):
    """
    éªŒè¯å‡½æ•°ï¼š
    ç¡®ä¿ Loss è®¡ç®—ä¸è®­ç»ƒæ—¶é€»è¾‘ä¸€è‡´ (Total = Main + Spatial)ã€‚
    ç”±äº Eval æ¨¡å¼ä¸‹æ¨¡å‹è¿”å› probsï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ç»„åˆ lossã€‚
    
    æŒ‡æ ‡è¯´æ˜ï¼š
    - Depth MAE: é¢„æµ‹æœŸæœ›æ·±åº¦ä¸GTæœŸæœ›æ·±åº¦ä¹‹é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    - è¿™æ˜¯ Soft GT ä¸‹æ›´åˆç†çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¡¡é‡"èšç„¦ä½ç½®"çš„å‡†ç¡®æ€§
    """
    model.eval()
    val_loss_accum = 0.0
    val_main_loss_accum = 0.0 # å•ç‹¬è®°å½•ä¸»æŸå¤±ä»¥ä¾¿è§‚å¯Ÿ
    val_spatial_loss_accum = 0.0 # å•ç‹¬è®°å½•ç©ºé—´æŸå¤±
    
    # æœŸæœ›æ·±åº¦è¯¯å·®ç´¯ç§¯
    depth_mae_accum = 0.0
    
    # å®ä¾‹åŒ–ç©ºé—´æŸå¤±è®¡ç®—æ¨¡å— (ç”¨äºéªŒè¯é›†)
    spatial_criterion = SpatialSmoothnessLoss(mode=loss_mode).to(device) if lambda_spatial > 0 else None
    
    os.makedirs(save_path, exist_ok=True)

    progress_bar = tqdm(
        val_loader, 
        desc=f"ğŸ“Š Val {dataset_name}",
        ncols=140, # ç¨å¾®å®½ä¸€ç‚¹æ˜¾ç¤ºæ›´å¤šä¿¡æ¯
        bar_format='{l_bar}{bar:30}{r_bar}',
        colour='blue'
    )

    with torch.no_grad():
        for i, (image_stack, soft_gt, stack_size) in enumerate(progress_bar):
            image_stack, soft_gt = image_stack.to(device), soft_gt.to(device)
            B, N, H, W = soft_gt.shape

            # æ¨ç†æ¨¡å¼ä¸‹ï¼ŒNetwork è¿”å›:
            # fused_image: [B, 1, H, W]
            # probs: [B, N, H, W] (å·²ç»ç»è¿‡ Softmax)
            fused_image, probs = model(image_stack)
            
            # === 1. è®¡ç®— Main Loss (Fidelity) ===
            main_loss = 0.0
            if loss_mode == 'ordered':
                # OT Loss (CDF L1)
                pred_cdf = torch.cumsum(probs, dim=1)
                gt_cdf = torch.cumsum(soft_gt, dim=1)
                main_loss = torch.mean(torch.abs(pred_cdf - gt_cdf)).item()
            else:
                # KL Divergence
                # probs å·²ç»æ˜¯ softmax ç»“æœï¼Œå– log å¾—åˆ° log_probs
                log_probs = torch.log(probs + 1e-8) 
                main_loss = F.kl_div(log_probs, soft_gt, reduction='batchmean').item()
            
            # === 2. è®¡ç®— Spatial Loss ===
            spatial_loss = 0.0
            if spatial_criterion is not None:
                # SpatialSmoothnessLoss æ¥å— probs
                spatial_loss = spatial_criterion(probs).item()
                
            # === 3. è®¡ç®— Total Loss ===
            total_batch_loss = main_loss + lambda_spatial * spatial_loss
            
            # ç´¯åŠ ç»Ÿè®¡
            val_loss_accum += total_batch_loss
            val_main_loss_accum += main_loss
            val_spatial_loss_accum += spatial_loss
            
            # === 4. è®¡ç®—æœŸæœ›æ·±åº¦è¯¯å·® (Expected Depth Error) ===
            # æ›´é€‚åˆ Soft GT çš„è¯„ä¼°æŒ‡æ ‡
            # æœŸæœ›æ·±åº¦ = sum(layer_index * probability)
            layer_indices = torch.arange(N, device=probs.device, dtype=torch.float32).view(1, N, 1, 1)
            
            pred_expected_depth = torch.sum(layer_indices * probs, dim=1)  # [B, H, W]
            gt_expected_depth = torch.sum(layer_indices * soft_gt, dim=1)  # [B, H, W]
            
            # æ·±åº¦ MAE (Mean Absolute Error)
            batch_depth_mae = torch.mean(torch.abs(pred_expected_depth - gt_expected_depth)).item()
            depth_mae_accum += batch_depth_mae

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                "Loss": f"{total_batch_loss:.4f}",
                "Main": f"{main_loss:.4f}",
                "Spa": f"{spatial_loss:.4f}",
                "MAE": f"{batch_depth_mae:.3f}"
            })

            # === 5. å¯è§†åŒ– (åªä¿å­˜æœ€åä¸€ä¸ª batch) ===
            if i == len(val_loader) - 1:
                visualization_path = os.path.join(save_path, f'epoch_{epoch}')
                
                # å¯è§†åŒ–æœŸæœ›æ·±åº¦å›¾ï¼ˆæ›´è¿ç»­ã€æ›´æœ‰æ„ä¹‰ï¼‰
                gt_depth_vis = gt_expected_depth.unsqueeze(1)  # [B, 1, H, W]
                pred_depth_vis = pred_expected_depth.unsqueeze(1)  # [B, 1, H, W]
                
                to_image(gt_depth_vis, epoch, 'depth_gt', visualization_path)
                to_image(pred_depth_vis, epoch, 'depth_pred', visualization_path)
                to_image(fused_image, epoch, 'fused_image', visualization_path)

    num_batches = len(val_loader)
    avg_total_loss = val_loss_accum / num_batches
    avg_main_loss = val_main_loss_accum / num_batches
    avg_depth_mae = depth_mae_accum / num_batches

    # è¿”å›: Total Loss, Main Loss, Depth MAE
    return (avg_total_loss, avg_main_loss, avg_depth_mae)

def main():
    # 1. è§£æå‚æ•°
    args = parse_args()
    print_banner()
    
    # 2. é…ç½®è·¯å¾„å’Œæ—¥å¿—
    # save_name åŠ ä¸Š mode åç¼€ï¼Œæ–¹ä¾¿åŒºåˆ†
    full_save_name = f"{args.save_name}_{args.loss_mode}"
    model_save_path = config_model_dir(resume=False, subdir_name=full_save_name)
    writer = SummaryWriter(log_dir=model_save_path)
    
    # 3. åˆ›å»º DataLoader
    train_loader, val_loaders = create_dataset_loaders(args)
    
    # 4. åˆå§‹åŒ–æ¨¡å‹
    model = StackMFF_V5()
    num_params = count_parameters(model)
    print_model_info(model, num_params)
    
    # 5. è®¾å¤‡é…ç½® (æ”¯æŒå•å¡/å¤šå¡)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if args.gpu_ids is not None:
         if len(args.gpu_ids) == 1:
             device = torch.device(f"cuda:{args.gpu_ids[0]}")
             model.to(device)
         else:
             model.to(device)
             model = nn.DataParallel(model, device_ids=args.gpu_ids)
    else:
        model.to(device)
        if torch.cuda.device_count() > 1:
            model = nn.DataParallel(model)

    print(f"ğŸ”§ Device: {device}")
    print(f"ğŸ“‰ Loss Mode: {args.loss_mode.upper()}")
    print(f"ğŸŒŠ Spatial Lambda: {args.lambda_spatial}")
    print_dataset_info(train_loader, val_loaders, args)
    
    # 6. åˆå§‹åŒ– Loss Function
    # ä½¿ç”¨æˆ‘ä»¬åœ¨ loss.py ä¸­å®šä¹‰çš„ FusionLoss
    criterion = FusionLoss(mode=args.loss_mode, lambda_spatial=args.lambda_spatial).to(device)
    
    # 7. ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = AdamW(model.parameters(), lr=args.lr)
    scheduler = ExponentialLR(optimizer, gamma=args.lr_decay)
    
    print_training_config(args, optimizer, scheduler)
    
    # 8. è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    best_epoch = -1
    start_time = time.time()
    val_results_data = []
    
    for epoch in range(args.num_epochs):
        train_loss = 0.0
        
        # --- Training ---
        if train_loader:
            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, args.num_epochs)
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('LR', scheduler.get_last_lr()[0], epoch)
        
        # --- Validation ---
        val_results = [] # å­˜å‚¨æ¯ä¸ªæ•°æ®é›†çš„ç»“æœ
        epoch_val_data = {'epoch': epoch + 1, 'train_loss': train_loss}
        
        current_epoch_val_loss_sum = 0.0
        
        for i, val_loader in enumerate(val_loaders):
            dataset_name = args.val_datasets[i] if i < len(args.val_datasets) else f"dataset_{i+1}"
            
            # ä¼ å…¥ loss_mode å’Œ lambda_spatialï¼Œç¡®ä¿éªŒè¯æŒ‡æ ‡ä¸è®­ç»ƒä¸€è‡´
            results = validate_dataset(
                model, val_loader, device, epoch, 
                os.path.join(model_save_path, f'val_{dataset_name}'), 
                dataset_name,
                args.loss_mode,
                args.lambda_spatial # ä¼ å…¥å‚æ•°
            )
            val_results.append(results)
            
            # results: (total_loss, main_loss, depth_mae)
            v_total_loss, v_main_loss, v_depth_mae = results
            current_epoch_val_loss_sum += v_total_loss
            
            writer.add_scalar(f'Loss/val/{dataset_name}/total', v_total_loss, epoch)
            writer.add_scalar(f'Loss/val/{dataset_name}/main', v_main_loss, epoch)
            writer.add_scalar(f'DepthMAE/val/{dataset_name}', v_depth_mae, epoch)
            
            epoch_val_data.update({
                f'val_{dataset_name}_total_loss': v_total_loss,
                f'val_{dataset_name}_main_loss': v_main_loss,
                f'val_{dataset_name}_depth_mae': v_depth_mae
            })
        
        val_results_data.append(epoch_val_data)
        
        # ä¿å­˜ CSV æ—¥å¿—
        pd.DataFrame(val_results_data).to_csv(os.path.join(model_save_path, 'results.csv'), index=False)
        
        # ä¿å­˜ Checkpoint
        save_dir = os.path.join(model_save_path, 'checkpoints')
        os.makedirs(save_dir, exist_ok=True)
        
        state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()
        if (epoch + 1) % 5 == 0:
            torch.save(state_dict, os.path.join(save_dir, f'epoch_{epoch}.pth'))
        
        # ä¿å­˜ Best Model (åŸºäºéªŒè¯é›†å¹³å‡ Total Loss)
        if val_loaders:
            avg_val_loss = current_epoch_val_loss_sum / len(val_loaders)
            
            improved = False
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                best_epoch = epoch
                improved = True
                torch.save(state_dict, os.path.join(model_save_path, 'best_model.pth'))
                
            print(f"Epoch {epoch+1} Summary | Train Loss: {train_loss:.4f} | Val Total Loss: {avg_val_loss:.4f} {'â­' if improved else ''}")

        scheduler.step()
    
    print_training_complete(start_time, model_save_path)
    writer.close()

if __name__ == "__main__":
    main()